//
//     Generated by class-dump 3.5 (64 bit) (Debug version compiled Sep 17 2017 16:24:48).
//
//     class-dump is Copyright (C) 1997-1998, 2000-2001, 2004-2015 by Steve Nygard.
//

#import "GPUImageOutput.h"

#import "AVCaptureAudioDataOutputSampleBufferDelegate-Protocol.h"
#import "AVCaptureVideoDataOutputSampleBufferDelegate-Protocol.h"

@class AVCaptureAudioDataOutput, AVCaptureDevice, AVCaptureDeviceInput, AVCaptureSession, AVCaptureVideoDataOutput, GLProgram, GPUImageFramebuffer, GPUImageTwoInputFilter, NSDate, NSObject, NSString, VNDetectFaceLandmarksRequest, VNSequenceRequestHandler;
@protocol GPUImageVideoCameraDelegate, OS_dispatch_queue, OS_dispatch_semaphore;

@interface GPUImageVideoCamera : GPUImageOutput <AVCaptureVideoDataOutputSampleBufferDelegate, AVCaptureAudioDataOutputSampleBufferDelegate>
{
    unsigned long long numberOfFramesCaptured;
    double totalFrameTimeDuringCapture;
    AVCaptureSession *_captureSession;
    AVCaptureDevice *_inputCamera;
    AVCaptureDevice *_microphone;
    AVCaptureDeviceInput *videoInput;
    AVCaptureVideoDataOutput *videoOutput;
    _Bool capturePaused;
    int outputRotation;
    int internalRotation;
    int internalRotation2;
    NSObject<OS_dispatch_semaphore> *frameRenderingSemaphore;
    _Bool captureAsYUV;
    unsigned int luminanceTexture;
    unsigned int chrominanceTexture;
    id <GPUImageVideoCameraDelegate> _delegate;
    AVCaptureDeviceInput *audioInput;
    AVCaptureAudioDataOutput *audioOutput;
    NSDate *startingCaptureTime;
    NSObject<OS_dispatch_queue> *cameraProcessingQueue;
    NSObject<OS_dispatch_queue> *audioProcessingQueue;
    GLProgram *yuvConversionProgram;
    int yuvConversionPositionAttribute;
    int yuvConversionTextureCoordinateAttribute;
    int yuvConversionLuminanceTextureUniform;
    int yuvConversionChrominanceTextureUniform;
    int yuvConversionMatrixUniform;
    const float *_preferredConversion;
    _Bool isFullYUVRange;
    int imageBufferWidth;
    int imageBufferHeight;
    void *pImageBuffer;
    _Bool addedAudioInputsDueToEncodingTarget;
    double currentFrameTime;
    double nextFrameTime;
    double timePerFrame;
    int mFrames;
    GPUImageFramebuffer *lastOutputFramebuffer;
    _Bool filledZeroData;
    _Bool _runBenchmark;
    _Bool _horizontallyMirrorFrontFacingCamera;
    _Bool _horizontallyMirrorRearFacingCamera;
    _Bool _useStillImage;
    _Bool _degreefps;
    int _frameRate;
    float _fillZeroAudioDuration;
    NSString *_captureSessionPreset;
    long long _outputImageOrientation;
    GPUImageTwoInputFilter *_mixFilter;
    CDUnknownBlockType _getFaceLandmarks;
    VNSequenceRequestHandler *_handler;
    VNDetectFaceLandmarksRequest *_request;
}

+ (_Bool)isFrontFacingCameraPresent;
+ (_Bool)isBackFacingCameraPresent;
+ (int)pasteLogToBuf:(char *)arg1 length:(int)arg2;
+ (id)dumpLog;
+ (void)cleanLog;
+ (id)getSDKVersion;
@property(retain, nonatomic) VNDetectFaceLandmarksRequest *request; // @synthesize request=_request;
@property(retain, nonatomic) VNSequenceRequestHandler *handler; // @synthesize handler=_handler;
@property(nonatomic) _Bool degreefps; // @synthesize degreefps=_degreefps;
@property(copy, nonatomic) CDUnknownBlockType getFaceLandmarks; // @synthesize getFaceLandmarks=_getFaceLandmarks;
@property float fillZeroAudioDuration; // @synthesize fillZeroAudioDuration=_fillZeroAudioDuration;
@property(retain, nonatomic) GPUImageTwoInputFilter *mixFilter; // @synthesize mixFilter=_mixFilter;
@property(nonatomic) _Bool useStillImage; // @synthesize useStillImage=_useStillImage;
@property(nonatomic) _Bool horizontallyMirrorRearFacingCamera; // @synthesize horizontallyMirrorRearFacingCamera=_horizontallyMirrorRearFacingCamera;
@property(nonatomic) _Bool horizontallyMirrorFrontFacingCamera; // @synthesize horizontallyMirrorFrontFacingCamera=_horizontallyMirrorFrontFacingCamera;
@property(nonatomic) id <GPUImageVideoCameraDelegate> delegate; // @synthesize delegate=_delegate;
@property(nonatomic) long long outputImageOrientation; // @synthesize outputImageOrientation=_outputImageOrientation;
@property(nonatomic) _Bool runBenchmark; // @synthesize runBenchmark=_runBenchmark;
@property(readonly) AVCaptureDevice *inputCamera; // @synthesize inputCamera=_inputCamera;
@property(readonly, retain, nonatomic) AVCaptureSession *captureSession; // @synthesize captureSession=_captureSession;
@property(copy, nonatomic) NSString *captureSessionPreset; // @synthesize captureSessionPreset=_captureSessionPreset;
- (void).cxx_destruct;
- (int)bufferHeight;
- (int)bufferWidth;
- (void *)getImageBuffer;
- (void)setDowngradeFps:(unsigned long long)arg1;
- (void)updateOrientationSendToTargets;
- (void)setAudioEncodingTarget:(id)arg1;
- (void)captureOutput:(id)arg1 didOutputSampleBuffer:(struct opaqueCMSampleBuffer *)arg2 fromConnection:(id)arg3;
- (_Bool)dropFrame:(struct opaqueCMSampleBuffer *)arg1;
- (void)resetBenchmarkAverage;
- (double)averageFrameDurationDuringCapture;
- (void)convertYUVToRGBOutput;
- (void)processAudioSampleBuffer:(struct opaqueCMSampleBuffer *)arg1;
- (void)processVideoSampleBuffer:(struct opaqueCMSampleBuffer *)arg1;
- (void)updateTargetsForVideoCameraUsingCacheTextureAtWidth:(int)arg1 height:(int)arg2 time:(CDStruct_1b6d18a9)arg3;
- (id)videoCaptureConnection;
@property int frameRate; // @synthesize frameRate=_frameRate;
@property(readonly, getter=isFrontFacingCameraPresent) _Bool frontFacingCameraPresent;
@property(readonly, getter=isBackFacingCameraPresent) _Bool backFacingCameraPresent;
- (long long)cameraPosition;
@property(readonly) _Bool cameraTorchIsOn;
- (_Bool)turnCameraTorchOn:(_Bool)arg1;
- (void)rotateCamera;
- (void)resumeCameraCapture;
- (void)pauseCameraCapture;
- (void)stopCameraCapture;
- (void)startCameraCapture;
- (void)addTarget:(id)arg1 atTextureLocation:(long long)arg2;
@property(nonatomic) double videoZoomFactor;
- (void)focusAtPoint:(struct CGPoint)arg1;
- (void)setCaptureContinuousAutoFocusMode;
- (void)setSubjectAreaChangeMonitoringEnabled;
- (void)onCaptureDeviceSubjectAreaDidChangeNotification:(id)arg1;
- (void)unregisterNotification;
- (void)registerNotification;
- (void)removeInputsAndOutputs;
- (_Bool)removeAudioInputsAndOutputs;
- (_Bool)addAudioInputsAndOutputs;
- (void)dealloc;
- (id)framebufferForOutput;
- (id)initWithSessionPreset:(id)arg1 cameraPosition:(long long)arg2 usesApplicationAudioSession:(_Bool)arg3;
- (id)initWithSessionPreset:(id)arg1 cameraPosition:(long long)arg2;
- (id)init;

// Remaining properties
@property(readonly, copy) NSString *debugDescription;
@property(readonly, copy) NSString *description;
@property(readonly) unsigned long long hash;
@property(readonly) Class superclass;

@end

